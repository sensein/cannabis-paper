{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593eddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52813f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data from MMJ-Processed_data-2022_05_27-13_58-6858bbe.csv\n",
    "\n",
    "\n",
    "def create_subs_df(group,ses,task,contrast):\n",
    "    effect_size_maps = glob.glob(f'../../../derivatives/task_analysis_volume/first_level/sub-{group}*/ses-{ses}/task-{task}/sub-{group}*_ses-{ses}_task-{task}_rec-unco_run-1_contrast-{contrast}_effect_size.nii.gz')\n",
    "    non_img_data = pd.read_csv(f\"../../../sourcedata/non_imaging_data/MMJ-Processed_data-2022_05_27-13_58-6858bbe.csv\",low_memory=False)\n",
    "\n",
    "    #need to find subjects that have data for this contrast\n",
    "    subs = [path.split('/sub-')[1].split('/')[0] for path in effect_size_maps if path]\n",
    "    subs = ['_'.join([s for s in re.split(r'(MM|HC)', sub) if s]) for sub in subs]\n",
    "    df_subs = pd.DataFrame(subs,columns=['subs'])\n",
    "\n",
    "\n",
    "    #add columns for male and female, that will then be combined to create the group average \n",
    "    grouped_sex = non_img_data.groupby(\"IDS.CHR.Subject\")[\"SBJ.CHR.Sex\"].agg(\"first\")\n",
    "    dict_sex = grouped_sex.to_dict()\n",
    "    df_subs = pd.concat([df_subs,pd.get_dummies(df_subs['subs'].map(dict_sex))],axis=1,copy=False)\n",
    "\n",
    "    #add age, mean-centered\n",
    "    grouped_age = non_img_data.groupby(\"IDS.CHR.Subject\")[\"SBJ.INT.Age\"].agg(\"first\")\n",
    "    dict_age = grouped_age.to_dict()\n",
    "    df_subs['age'] = df_subs['subs'].map(dict_age)\n",
    "    df_subs['age'] = df_subs['age'] - df_subs['age'].mean()\n",
    "\n",
    "    #add CUDIT summed score, mean-centered\n",
    "    if group == 'HC': \n",
    "        grouped_HC_baseline_cudit = non_img_data[non_img_data['SSS.CHR.Time_point'] == 'Screening'].groupby('IDS.CHR.Subject')['INV.INT.CUDIT.Summed_score'].agg(\"first\")\n",
    "        dict_HC_baseline_cudit = grouped_HC_baseline_cudit.to_dict()\n",
    "        df_subs['total_cudit'] = df_subs['subs'].map(dict_HC_baseline_cudit)\n",
    "        df_subs['total_cudit'] = df_subs['total_cudit'] - df_subs['total_cudit'].mean()\n",
    "\n",
    "    else:\n",
    "        if ses == 'baseline':\n",
    "            dict_MM_baseline_cudit = non_img_data[non_img_data['SSS.CHR.Time_point'] == 'Baseline'].groupby('IDS.CHR.Subject')['INV.INT.CUDIT.Summed_score'].agg(\"first\").to_dict()\n",
    "            df_subs['total_cudit'] = df_subs['subs'].map(dict_MM_baseline_cudit)\n",
    "            df_subs['total_cudit'] = df_subs['total_cudit'] - df_subs['total_cudit'].mean()\n",
    "            df_subs['total_cudit'].fillna(0, inplace=True)\n",
    "\n",
    "        else:\n",
    "            dict_MM_1year_cudit = non_img_data[non_img_data['SSS.CHR.Time_point'] == 'One year'].groupby('IDS.CHR.Subject')['INV.INT.CUDIT.Summed_score'].agg(\"first\").to_dict()\n",
    "            df_subs['total_cudit'] = df_subs['subs'].map(dict_MM_1year_cudit)\n",
    "            df_subs['total_cudit'] = df_subs['total_cudit'] - df_subs['total_cudit'].mean()\n",
    "\n",
    "    #add frequency of THC use per month, mean-centered\n",
    "    freq_dict = {'Once or more per day':7,\n",
    "     '5-6 days a week':6,\n",
    "     '3-4 days a week':5,\n",
    "     '1-2 days a week':4,\n",
    "     'Less than once a week':3,\n",
    "     'Less than once every two weeks':2,\n",
    "     'Less than once a month':1,\n",
    "     None:0,\n",
    "     }\n",
    "\n",
    "    if group == 'HC':\n",
    "        #results from screening visit (using this for consistency since CUDIT-R was also collected at screening visit)\n",
    "        dict_HC_screening_THC = non_img_data[non_img_data['SSS.CHR.Time_point'] == 'Screening'].groupby('IDS.CHR.Subject')['TLF.CHR.THC.Frequency_in_month'].agg(\"last\").to_dict()\n",
    "        dict_HC_screening_THC_num = {k:freq_dict[v] for k,v in dict_HC_screening_THC.items()}\n",
    "        df_subs['THC_freq_month'] = df_subs['subs'].map(dict_HC_screening_THC_num)\n",
    "        df_subs['THC_freq_month'] = df_subs['THC_freq_month'] - df_subs['THC_freq_month'].mean()\n",
    "\n",
    "    else:\n",
    "        if ses == 'baseline':     \n",
    "            #results from MRI visit (using this for consistency since CUDIT-R was also collected at MRI visit)\n",
    "            dict_MM_MRIvisit_THC = non_img_data[non_img_data['SSS.CHR.Time_point'] == 'Baseline'].groupby('IDS.CHR.Subject')['TLF.CHR.THC.Frequency_in_month'].agg(\"first\").to_dict()\n",
    "            dict_MM_MRIvisit_THC_num = {k:freq_dict[v] for k,v in dict_MM_MRIvisit_THC.items()}\n",
    "            df_subs['THC_freq_month'] = df_subs['subs'].map(dict_MM_MRIvisit_THC_num)\n",
    "            df_subs['THC_freq_month'] = df_subs['THC_freq_month'] - df_subs['THC_freq_month'].mean()\n",
    "\n",
    "        else:\n",
    "            dict_MM_MRIvisit_THC = non_img_data[non_img_data['SSS.CHR.Time_point'] == 'One year'].groupby('IDS.CHR.Subject')['TLF.CHR.THC.Frequency_in_month'].agg(\"first\").to_dict()\n",
    "            dict_MM_MRIvisit_THC_num = {k:freq_dict[v] for k,v in dict_MM_MRIvisit_THC.items()}\n",
    "            df_subs['THC_freq_month'] = df_subs['subs'].map(dict_MM_MRIvisit_THC_num)\n",
    "            df_subs['THC_freq_month'] = df_subs['THC_freq_month'] - df_subs['THC_freq_month'].mean()\n",
    "    \n",
    "    return df_subs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare matching data from nback_Accuracy_RTime and nback_Accuracy_RTime_HC\n",
    "\n",
    "def create_merged_df(df_subs,group,ses):\n",
    "    if group == 'HC':\n",
    "        nback_data = pd.read_csv(f\"../../../sourcedata/non_imaging_data/nback_RT_ACC/nback_Accuracy_RTime_HC.csv\",low_memory=False)\n",
    "        nback_data=nback_data.rename(columns = {'subject':'subs'})\n",
    "    else:\n",
    "        nback_data = pd.read_csv(f\"../../../sourcedata/non_imaging_data/nback_RT_ACC/nback_Accuracy_RTime.csv\",low_memory=False)\n",
    "        nback_data=nback_data.rename(columns = {'subject':'subs'})\n",
    "        if ses == 'baseline':\n",
    "            nback_data=nback_data[nback_data['timepoint']=='baseline']\n",
    "        else:\n",
    "            nback_data=nback_data[nback_data['timepoint']=='1year']\n",
    "\n",
    "    nback_data.drop(columns=['timepoint'], inplace = True)\n",
    "\n",
    "    for column in nback_data.columns[1:]:\n",
    "        nback_data[column] = nback_data[column] - nback_data[column].mean()\n",
    "        nback_data[column].fillna(0, inplace=True)\n",
    "\n",
    "    merged_data = pd.merge(df_subs, nback_data, on='subs')\n",
    "    \n",
    "    return merged_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_paired_difference_distribution(MM_baseline_df,MM_1year_df,column):\n",
    "    \n",
    "    paired_differences = calc_paired_diff(MM_baseline_df,MM_1year_df,column)\n",
    "    \n",
    "    # Plot the distribution of the column using a histogram\n",
    "    plt.hist(paired_differences, bins='auto', edgecolor='black',label='Paired differences')\n",
    "    \n",
    "    # Add vertical lines for means\n",
    "    plt.axvline(np.mean(paired_differences), color='blue', linestyle='dashed', linewidth=2, label=f'Paired differences mean')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(f'{column} Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {column} Values')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c501d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_distributions(df1,df2,column):\n",
    "    plt.hist(df1[column], bins='auto', alpha=0.5, label=f'{df1}', edgecolor='black')\n",
    "    plt.hist(df2[column], bins='auto', alpha=0.5, label=f'{df2}', edgecolor='black')\n",
    "\n",
    "    # Add vertical lines for means\n",
    "    plt.axvline(df1[column].mean(), color='blue', linestyle='dashed', linewidth=2, label=f'{df1} mean')\n",
    "    plt.axvline(df2[column].mean(), color='orange', linestyle='dashed', linewidth=2, label=f'{df2} mean')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(f'{column} Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {column} Values')\n",
    "\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe085905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(df, column):\n",
    "\n",
    "    # Plot the distribution of the column using a histogram\n",
    "    plt.hist(df[column], bins='auto', edgecolor='black')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(f'{column} Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {column} Values')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae695c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(group,ses,task,contrast):\n",
    "    df_subs = create_subs_df(group,ses,task,contrast)\n",
    "    if group == 'MM':\n",
    "        df_subs = rm_CUD_baseline_subs(df_subs)\n",
    "    merged_data = create_merged_df(df_subs,group,ses)\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_CUD_baseline_subs(df_subs):\n",
    "    \n",
    "    #subs with CUD at baseline\n",
    "    excluded_subs = ['MM_014','MM_188','MM_197','MM_217','MM_228','MM_239','MM_241'] \n",
    "\n",
    "    #remove rows with subs that had CUD at baseline\n",
    "    df_subs = df_subs[~df_subs['subs'].isin(excluded_subs)]\n",
    "    \n",
    "    return df_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform t-test \n",
    "\n",
    "def t_test_between_HC_and_MM_baseline(HC_baseline_df,MM_baseline_df):\n",
    "    dict_results={}\n",
    "    \n",
    "    for column in HC_baseline_df.columns[6:]:\n",
    "        \n",
    "        x1 = HC_baseline_df[column]\n",
    "        x2 = MM_baseline_df[column]\n",
    "        pop_mean = np.mean(x2)-np.mean(x1)\n",
    "        \n",
    "        tstat, pval = stats.ttest_ind(x1, x2, axis=0, equal_var=True, nan_policy='raise', permutations=None, alternative='two-sided')\n",
    "        \n",
    "        rounded_pop_mean = round(pop_mean,3)\n",
    "        rounded_pval = round(pval,3)\n",
    "        \n",
    "        dict_results[column] = {'difference of means':rounded_pop_mean, 'p value':rounded_pval}\n",
    "    \n",
    "    return dict_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f80084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_paired_diff(MM_baseline_df,MM_1year_df,column):\n",
    "    \n",
    "    MM_baseline_subs = MM_baseline_df['subs']\n",
    "    MM_1year_subs = MM_1year_df['subs']\n",
    "    \n",
    "    MM_paired_subs = set(MM_baseline_subs).intersection(set(MM_1year_subs))\n",
    "        \n",
    "    xdiff = [float(MM_1year_df[MM_1year_df['subs'] == sub][column])-float(MM_baseline_df[MM_baseline_df['subs'] == sub][column]) for sub in MM_paired_subs]\n",
    "    \n",
    "    return xdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcd1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform t-test \n",
    "\n",
    "def paired_t_test_between_MM_baseline_1year(MM_baseline_df,MM_1year_df):\n",
    "    dict_results={}\n",
    "    \n",
    "    for column in MM_baseline_df.columns[6:]:\n",
    "        \n",
    "        xdiff = calc_paired_diff(MM_baseline_df,MM_1year_df,column)\n",
    "        #1year - baseline difference\n",
    "        pop_mean = np.mean(xdiff)\n",
    "        \n",
    "        tstat, pval = stats.ttest_1samp(xdiff, popmean=0, nan_policy='raise', alternative='two-sided')\n",
    "\n",
    "        rounded_pop_mean = round(pop_mean,3)\n",
    "        rounded_pval = round(pval,3)\n",
    "        \n",
    "        dict_results[column] = {'mean difference':rounded_pop_mean, 'p value':rounded_pval}\n",
    "        \n",
    "    return dict_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f576e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df,group,ses):\n",
    "    \n",
    "    #create paths to output dir if not exist\n",
    "    derivatives_path = '../../../derivatives'\n",
    "    nilearn_output_path = os.path.join(derivatives_path, 'behavioral', 'task-nback')\n",
    "    if not os.path.isdir(nilearn_output_path):\n",
    "        os.makedirs (nilearn_output_path)\n",
    "        \n",
    "    df.to_csv(f'../../../derivatives/behavioral/task-nback/nback-ACC_nback-RT_group-{group}_ses-{ses}.csv')\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26cf3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [('HC','baseline'),('MM','baseline'),('MM','1year')]\n",
    "\n",
    "input_dfs = {}\n",
    "output_dfs = {}\n",
    "\n",
    "for group,ses in inputs:\n",
    "    df = create_df(group,ses,'nback','twoback-zeroback')\n",
    "    save_df(df,group,ses)\n",
    "    input_dfs[f'{group}_{ses}_df'] = df\n",
    "    #if desired a distribution for any variable of an individual group can be plotted\n",
    "    #plot_distribution(df,'RT_2b_cor')\n",
    "\n",
    "   \n",
    "ttest_2samp = t_test_between_HC_and_MM_baseline(input_dfs['HC_baseline_df'],input_dfs['MM_baseline_df'])\n",
    "output_dfs[f'HC_baseline_vs._MM_baseline_ttest'] = pd.DataFrame.from_dict(ttest_2samp)\n",
    "\n",
    "#if desired the two distributions for any variable can be plotted together with the means highlighted \n",
    "#plot_two_distributions(input_dfs['HC_baseline_df'],input_dfs['MM_baseline_df'],'RT_all_cor')\n",
    "\n",
    "\n",
    "ttest_paired = paired_t_test_between_MM_baseline_1year(input_dfs['MM_baseline_df'],input_dfs['MM_1year_df'])\n",
    "output_dfs[f'MM_baseline_vs._MM_1year_paired_ttest'] = pd.DataFrame.from_dict(ttest_paired)\n",
    "\n",
    "#if desired the difference distributions for any variable can be plotted together with the mean highlighted \n",
    "#plot_paired_difference_distribution(input_dfs['MM_baseline_df'],input_dfs['MM_1year_df'],'RT_all_cor')\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for title in output_dfs.keys():\n",
    "    df = output_dfs[title]\n",
    "    df['comparison'] = [title, np.nan]\n",
    "    df.rename(columns={'ACC_all': 'Combined accuracy', 'RT_all_cor': 'Combined reaction time', \n",
    "                               'ACC_0b': 'Accuracy of zero-back trials', 'RT_0b_cor': 'Reaction time of zero-back trials', \n",
    "                               'ACC_2b': 'Accuracy of two-back trials', 'RT_2b_cor': 'Reaction time of two-back trials'}, inplace=True)\n",
    "\n",
    "    final_df = pd.concat([final_df,df])\n",
    "\n",
    "final_df = final_df.T \n",
    "\n",
    "display(final_df)\n",
    "final_df.to_csv(f'../../../derivatives/behavioral/task-nback/nback-ACC_nback-RT_comparison.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
